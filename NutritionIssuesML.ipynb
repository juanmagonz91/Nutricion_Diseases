{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2gf9AH-jD21",
        "outputId": "99a567b1-1eda-4147-9e4d-ca6fd35710ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "   Ages  Gender  Height  Weight     Activity Level Dietary Preference  \\\n",
            "0    25    Male     180      80  Moderately Active           Omnivore   \n",
            "1    32  Female     165      65     Lightly Active         Vegetarian   \n",
            "2    48    Male     175      95          Sedentary              Vegan   \n",
            "3    55  Female     160      70        Very Active           Omnivore   \n",
            "4    62    Male     170      85          Sedentary         Vegetarian   \n",
            "\n",
            "   Daily Calorie Target  Protein  Sugar  Sodium  Calories  Carbohydrates  \\\n",
            "0                  2000      120  125.0    24.0      2020            250   \n",
            "1                  1600       80  100.0    16.0      1480            200   \n",
            "2                  2200      100  150.0    20.0      2185            300   \n",
            "3                  2500      140  175.0    28.0      2680            350   \n",
            "4                  2000       80  125.0    16.0      1815            250   \n",
            "\n",
            "   Fiber  Fat                               Breakfast Suggestion  \\\n",
            "0   30.0   60                      Oatmeal with berries and nuts   \n",
            "1   24.0   40                         Tofu scramble with veggies   \n",
            "2   36.0   65                  Tofu and veggie breakfast burrito   \n",
            "3   42.0   80                Greek yogurt with granola and fruit   \n",
            "4   30.0   55  Scrambled eggs with whole wheat toast and avocado   \n",
            "\n",
            "                             Lunch Suggestion  \\\n",
            "0     Grilled chicken salad with mixed greens   \n",
            "1          Lentil soup with whole wheat bread   \n",
            "2      Black bean burger on a whole wheat bun   \n",
            "3              Chicken and vegetable stir-fry   \n",
            "4  Quinoa salad with chickpeas and vegetables   \n",
            "\n",
            "                    Dinner Suggestion           Snack Suggestion  \\\n",
            "0      Salmon with roasted vegetables    Greek yogurt with fruit   \n",
            "1  Vegetable stir-fry with brown rice   Apple with almond butter   \n",
            "2          Lentil and vegetable curry                  Trail mix   \n",
            "3        Turkey chili with brown rice  Banana with peanut butter   \n",
            "4     Vegetarian chili with cornbread          Fruit and nut mix   \n",
            "\n",
            "                                    Disease  \n",
            "0                               Weight Gain  \n",
            "1  Weight Gain, Hypertension, Heart Disease  \n",
            "2                               Weight Gain  \n",
            "3                               Weight Gain  \n",
            "4                               Weight Gain  \n",
            "              Ages       Height       Weight  Daily Calorie Target  \\\n",
            "count  1698.000000  1698.000000  1698.000000           1698.000000   \n",
            "mean     43.961720   174.130153    78.064193           2275.171967   \n",
            "std      15.915002    13.420936    16.949264            558.812405   \n",
            "min      18.000000   150.000000    48.000000           1200.000000   \n",
            "25%      30.000000   163.250000    64.000000           1800.000000   \n",
            "50%      42.000000   174.000000    78.000000           2200.000000   \n",
            "75%      57.000000   185.000000    91.000000           2689.000000   \n",
            "max      79.000000   200.000000   119.000000           4364.000000   \n",
            "\n",
            "           Protein        Sugar       Sodium     Calories  Carbohydrates  \\\n",
            "count  1698.000000  1698.000000  1698.000000  1698.000000    1698.000000   \n",
            "mean    139.898115   126.192580    27.979623  2196.440518     252.385159   \n",
            "std      53.326588    34.938902    10.665318   571.089569      69.877804   \n",
            "min      50.000000    60.000000    10.000000   990.000000     120.000000   \n",
            "25%     100.000000   100.000000    20.000000  1770.250000     200.000000   \n",
            "50%     136.000000   124.000000    27.200000  2146.000000     248.000000   \n",
            "75%     174.000000   150.000000    34.800000  2549.750000     300.000000   \n",
            "max     327.000000   218.000000    65.400000  4357.000000     436.000000   \n",
            "\n",
            "             Fiber          Fat  \n",
            "count  1698.000000  1698.000000  \n",
            "mean     30.286219    69.700824  \n",
            "std       8.385337    21.430707  \n",
            "min      14.400000    30.000000  \n",
            "25%      24.000000    52.000000  \n",
            "50%      29.760000    69.000000  \n",
            "75%      36.000000    85.000000  \n",
            "max      52.320000   145.000000  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1698 entries, 0 to 1697\n",
            "Data columns (total 19 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Ages                  1698 non-null   int64  \n",
            " 1   Gender                1698 non-null   object \n",
            " 2   Height                1698 non-null   int64  \n",
            " 3   Weight                1698 non-null   int64  \n",
            " 4   Activity Level        1698 non-null   object \n",
            " 5   Dietary Preference    1698 non-null   object \n",
            " 6   Daily Calorie Target  1698 non-null   int64  \n",
            " 7   Protein               1698 non-null   int64  \n",
            " 8   Sugar                 1698 non-null   float64\n",
            " 9   Sodium                1698 non-null   float64\n",
            " 10  Calories              1698 non-null   int64  \n",
            " 11  Carbohydrates         1698 non-null   int64  \n",
            " 12  Fiber                 1698 non-null   float64\n",
            " 13  Fat                   1698 non-null   int64  \n",
            " 14  Breakfast Suggestion  1698 non-null   object \n",
            " 15  Lunch Suggestion      1698 non-null   object \n",
            " 16  Dinner Suggestion     1698 non-null   object \n",
            " 17  Snack Suggestion      1698 non-null   object \n",
            " 18  Disease               1698 non-null   object \n",
            "dtypes: float64(3), int64(8), object(8)\n",
            "memory usage: 252.2+ KB\n",
            "None\n",
            "Ages                    0\n",
            "Gender                  0\n",
            "Height                  0\n",
            "Weight                  0\n",
            "Activity Level          0\n",
            "Dietary Preference      0\n",
            "Daily Calorie Target    0\n",
            "Protein                 0\n",
            "Sugar                   0\n",
            "Sodium                  0\n",
            "Calories                0\n",
            "Carbohydrates           0\n",
            "Fiber                   0\n",
            "Fat                     0\n",
            "Breakfast Suggestion    0\n",
            "Lunch Suggestion        0\n",
            "Dinner Suggestion       0\n",
            "Snack Suggestion        0\n",
            "Disease                 0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Leer el archivo CSV\n",
        "df = pd.read_csv('/content/drive/My Drive/Beca bootcamp/Food_and_Nutrition__.csv')\n",
        "\n",
        "# Inspección inicial\n",
        "print(df.head())\n",
        "print(df.describe())\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1: Preprocesamiento de Datos\n",
        "\n",
        "**Limpieza de Datos:**\n",
        "Tratar los valores nulos utilizando técnicas adecuadas (imputación, eliminación, etc.).\n",
        "\n",
        "Manejar los outliers mediante técnicas de filtrado o transformación.\n",
        "\n",
        "**Transformación de Columnas:**\n",
        "\n",
        "Utilizar ColumnTransformer para aplicar transformaciones específicas a diferentes columnas.\n",
        "\n",
        "Realizar codificación de variables categóricas utilizando técnicas como One-Hot Encoding.\n",
        "\n",
        "Escalar las variables numéricas usando StandardScaler u otros métodos de normalización.\n",
        "\n",
        "**Creación de Pipelines:**\n",
        "\n",
        "Crear pipelines utilizando Pipeline de sklearn para automatizar el preprocesamiento de datos y asegurar la reproducibilidad.\n",
        "\n",
        "Incluir todos los pasos de preprocesamiento en el pipeline.\n",
        "\n",
        "# Parte 2: Selección de Técnica de Machine Learning\n",
        "\n",
        "**Entrenamiento Inicial:**\n",
        "\n",
        "Entrenar múltiples modelos de machine learning (por ejemplo, Regresión Lineal, KNN, Árbol de Decisión, Random Forest, XGBoost, LGBM).\n",
        "\n",
        "Evaluar los modelos utilizando validación cruzada y seleccionar el modelo con el mejor rendimiento inicial.\n",
        "\n",
        "**Comparación de Modelos:**\n"
      ],
      "metadata": {
        "id": "5mkXSmfbjUTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ---- Limpieza de Datos ----\n",
        "# Tratar valores nulos\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "imputer_num = SimpleImputer(strategy='mean')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
        "\n",
        "# Manejar outliers mediante winsorización (ajustar valores extremos)\n",
        "def winsorize(series, low=0.01, high=0.99):\n",
        "    return series.clip(lower=series.quantile(low), upper=series.quantile(high))\n",
        "\n",
        "for col in num_cols:\n",
        "    df[col] = winsorize(df[col])\n",
        "\n",
        "# ---- Transformación de Columnas ----\n",
        "# Definir columnas categóricas y numéricas\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.drop(\"Calories\")\n",
        "\n",
        "# Preprocesadores\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Crear ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ---- División de Datos ----\n",
        "X = df.drop(columns=['Calories'])\n",
        "y = df['Calories']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ---- Creación de Pipelines y Modelos ----\n",
        "models = {\n",
        "    'Regresión Lineal': LinearRegression(),\n",
        "    'KNN': KNeighborsRegressor(),\n",
        "    'Árbol de Decisión': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'XGBoost': XGBRegressor(),\n",
        "    'LightGBM': LGBMRegressor()\n",
        "}\n",
        "\n",
        "# Evaluación inicial\n",
        "resultados = []\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model)\n",
        "    ])\n",
        "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "    rmse_scores = np.sqrt(-scores)\n",
        "    resultados.append({\n",
        "        'Modelo': name,\n",
        "        'RMSE Promedio': rmse_scores.mean(),\n",
        "        'RMSE Std Dev': rmse_scores.std()\n",
        "    })\n",
        "\n",
        "# Crear un DataFrame con los resultados\n",
        "resultados_df = pd.DataFrame(resultados).sort_values(by='RMSE Promedio')\n",
        "print(resultados_df)\n",
        "\n",
        "# ---- Selección del Mejor Modelo ----\n",
        "mejor_modelo_nombre = resultados_df.iloc[0]['Modelo']\n",
        "mejor_modelo = models[mejor_modelo_nombre]\n",
        "\n",
        "pipeline_mejor = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', mejor_modelo)\n",
        "])\n",
        "\n",
        "# Entrenar el mejor modelo\n",
        "pipeline_mejor.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar en el conjunto de prueba\n",
        "y_pred = pipeline_mejor.predict(X_test)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"Mejor modelo: {mejor_modelo_nombre}\")\n",
        "print(f\"RMSE en el conjunto de prueba: {rmse_test:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mpdeKwfjhAT",
        "outputId": "3c212bbd-5acf-4ceb-92f7-77070e3e1137"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1463\n",
            "[LightGBM] [Info] Number of data points in the train set: 1086, number of used features: 68\n",
            "[LightGBM] [Info] Start training from score 2205.199541\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1468\n",
            "[LightGBM] [Info] Number of data points in the train set: 1086, number of used features: 69\n",
            "[LightGBM] [Info] Start training from score 2208.811999\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1472\n",
            "[LightGBM] [Info] Number of data points in the train set: 1086, number of used features: 69\n",
            "[LightGBM] [Info] Start training from score 2186.650056\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1454\n",
            "[LightGBM] [Info] Number of data points in the train set: 1087, number of used features: 69\n",
            "[LightGBM] [Info] Start training from score 2204.267912\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1471\n",
            "[LightGBM] [Info] Number of data points in the train set: 1087, number of used features: 69\n",
            "[LightGBM] [Info] Start training from score 2208.622421\n",
            "              Modelo  RMSE Promedio  RMSE Std Dev\n",
            "0   Regresión Lineal      11.814331      3.392346\n",
            "5           LightGBM      35.515586      4.500161\n",
            "4            XGBoost      39.711433      3.281327\n",
            "3      Random Forest      46.887618      1.694455\n",
            "2  Árbol de Decisión      83.671031      9.016696\n",
            "1                KNN     105.407843      4.719057\n",
            "Mejor modelo: Regresión Lineal\n",
            "RMSE en el conjunto de prueba: 14.4298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alparecer el modelo de Regresión Lineal fue el mejor en este caso, con un RMSE promedio más bajo durante la validación cruzada y un desempeño aceptable en el conjunto de prueba con un RMSE de 14.4298. Esto indica que la Regresión Lineal es adecuada para el problema planteado de predecir las calorías consumidas.\n",
        "\n",
        "Observaciones:\n",
        "LightGBM y XGBoost ofrecen resultados razonablemente buenos pero no superan el desempeño de la Regresión Lineal en este caso. Esto podría deberse a que la relación entre las variables es lineal, haciendo que los modelos complejos no agreguen valor significativo.\n",
        "\n",
        "KNN, Árbol de Decisión y Random Forest tienen peores resultados, indicando que no capturan bien la estructura de los datos para este problema."
      ],
      "metadata": {
        "id": "eMttuoPMna_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 3: Optimización de Hiperparámetros\n",
        "\n",
        "**GridSearchCV:**\n",
        "\n",
        "Implementar GridSearchCV para realizar una búsqueda exhaustiva de los mejores hiperparámetros para el modelo seleccionado.\n",
        "Definir el espacio de búsqueda para los hiperparámetros relevantes.\n",
        "\n",
        "**RandomizedSearchCV:**\n",
        "\n",
        "Implementar RandomizedSearchCV para realizar una búsqueda aleatoria de los mejores hiperparámetros, especialmente útil si el espacio de búsqueda es grande.\n",
        "\n",
        "**Optuna:**\n",
        "\n",
        "Implementar Optuna para una optimización avanzada de los hiperparámetros, aprovechando técnicas como la optimización bayesiana y el pruning.\n",
        "\n",
        "**Evaluación de Modelos Optimizados:**\n",
        "\n",
        "Entrenar el modelo con los mejores hiperparámetros encontrados y evaluar su rendimiento en el conjunto de prueba.\n",
        "Comparar el rendimiento del modelo optimizado con el modelo inicial."
      ],
      "metadata": {
        "id": "SCLIqqzZoZmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "# Definir las columnas numéricas y categóricas\n",
        "numerical_features = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Crear un transformador para las columnas numéricas y categóricas\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),  # Normalizar las variables numéricas\n",
        "        ('cat', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputar valores faltantes en categorías\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))    # Aplicar One-Hot Encoding\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Crear el pipeline con el preprocesador y el modelo de regresión lineal\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regression', LinearRegression())\n",
        "])\n",
        "\n",
        "# Definir el espacio de búsqueda de hiperparámetros\n",
        "param_grid = {\n",
        "    'regression__fit_intercept': [True, False],\n",
        "    'regression__copy_X': [True, False]\n",
        "}\n",
        "\n",
        "# Crear el GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Ajustar el modelo\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir los mejores hiperparámetros y el rendimiento\n",
        "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
        "print(f\"Mejor puntuación de validación (neg_mse): {grid_search.best_score_}\")\n",
        "\n",
        "# Evaluar el modelo optimizado\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"RMSE del modelo optimizado: {rmse}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf3I6pqznfZZ",
        "outputId": "ae943adf-ae49-4dfd-9cff-493525d48d69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores hiperparámetros: {'regression__copy_X': True, 'regression__fit_intercept': True}\n",
            "Mejor puntuación de validación (neg_mse): -151.0864223294411\n",
            "RMSE del modelo optimizado: 14.429764710724577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Supongamos que tienes un DataFrame X_train y X_test con datos numéricos y categóricos, y y_train, y_test como etiquetas\n",
        "# Definir las columnas numéricas y categóricas\n",
        "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Crear el transformador para las columnas\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='mean')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numerical_cols),\n",
        "        ('cat', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ]), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Crear el pipeline completo con el preprocesamiento y la regresión lineal\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regression', LinearRegression())\n",
        "])\n",
        "\n",
        "# Definir el espacio de búsqueda para los hiperparámetros\n",
        "param_grid = {\n",
        "    'regression__fit_intercept': [True, False],\n",
        "    'regression__copy_X': [True, False]\n",
        "}\n",
        "\n",
        "# Definir RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid, n_iter=10, cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# Ajustar el modelo\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir los mejores hiperparámetros y el rendimiento\n",
        "print(f\"Mejores hiperparámetros: {random_search.best_params_}\")\n",
        "print(f\"Mejor puntuación de validación (neg_mse): {random_search.best_score_}\")\n",
        "\n",
        "# Obtener el mejor modelo de RandomizedSearchCV\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Realizar predicciones sobre el conjunto de prueba\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calcular el MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Calcular el RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Mostrar el RMSE\n",
        "print(f\"RMSE del modelo optimizado con RandomizedSearch: {rmse}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HinZtyn8pHvs",
        "outputId": "ce68fa82-222e-40c6-d983-8d90cec977c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Mejores hiperparámetros: {'regression__fit_intercept': True, 'regression__copy_X': True}\n",
            "Mejor puntuación de validación (neg_mse): 0.9995200166811612\n",
            "RMSE del modelo optimizado con RandomizedSearch: 14.429764710724577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando GridSearch y RandomizarGS, no hubo mejoras en la busqueda de hiperparametros. Sin embargo, el modelo tiene una buena puntuación de validación."
      ],
      "metadata": {
        "id": "HAm1UcXOvXqs"
      }
    }
  ]
}